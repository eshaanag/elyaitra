import os
from dotenv import load_dotenv
import google.generativeai as genai
from langchain.text_splitter import RecursiveCharacterTextSplitter

from app.ai_engine.chroma_client import get_collection

print("ğŸ”¥ğŸ”¥ğŸ”¥ INGEST MODULE LOADED ğŸ”¥ğŸ”¥ğŸ”¥")

# --------------------------------------------------
# ENV
# --------------------------------------------------
load_dotenv()

API_KEY = os.getenv("GEMINI_API_KEY")
print("ğŸ”‘ GEMINI KEY EXISTS:", bool(API_KEY))

if not API_KEY:
    raise RuntimeError("âŒ GEMINI_API_KEY not set")

genai.configure(api_key=API_KEY)

SUBJECT = "chemistry"

# --------------------------------------------------
# PATHS
# --------------------------------------------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
APP_DIR = os.path.dirname(BASE_DIR)
BACKEND_DIR = os.path.dirname(APP_DIR)

DATA_PATH = os.path.join(BACKEND_DIR, "syllabus_data", SUBJECT)

print("ğŸ“ DATA_PATH =", DATA_PATH)

if not os.path.exists(DATA_PATH):
    raise RuntimeError(f"âŒ syllabus_data not found at {DATA_PATH}")

print("ğŸ“„ Files found:", os.listdir(DATA_PATH))

# --------------------------------------------------
# GET CHROMA COLLECTION
# --------------------------------------------------
print("ğŸ”Œ Getting Chroma collection...")
collection = get_collection(SUBJECT)
print("âœ… Got Chroma collection")

# --------------------------------------------------
# SPLITTER
# --------------------------------------------------
splitter = RecursiveCharacterTextSplitter(
    chunk_size=300,
    chunk_overlap=50
)

# --------------------------------------------------
# EMBED
# --------------------------------------------------
def embed(text: str) -> list[float]:
    print("ğŸ§  Embedding chunk...")
    result = genai.embed_content(
        model="models/text-embedding-004",
        content=text
    )
    return result["embedding"]

# --------------------------------------------------
# INGEST
# --------------------------------------------------
def ingest():
    print("ğŸš€ INGEST() STARTED")

    # Clear collection
    try:
        collection.delete(where={})
        print("ğŸ§¹ Cleared collection")
    except Exception as e:
        print("âš ï¸ Could not clear collection:", e)

    doc_id = 0
    files_processed = 0
    chunks_added = 0

    for file in os.listdir(DATA_PATH):
        print("ğŸ‘€ Found file:", file)

        if not file.lower().endswith(".txt"):
            print("â­ï¸ Skipping non-txt:", file)
            continue

        unit = file.replace("unit", "").replace(".txt", "")
        print(f"ğŸ“„ Reading: {file} | unit: {unit}")
        files_processed += 1

        path = os.path.join(DATA_PATH, file)
        print("ğŸ“‚ Opening:", path)

        with open(path, "r", encoding="utf-8") as f:
            text = f.read().strip()

        print("ğŸ“ File length:", len(text))

        if not text:
            print("âš ï¸ Empty file:", file)
            continue

        chunks = splitter.split_text(text)
        print("âœ‚ï¸ Chunks created:", len(chunks))

        for chunk in chunks:
            print("â• Adding chunk", doc_id)

            collection.add(
                documents=[chunk],
                embeddings=[embed(chunk)],
                metadatas=[{
                    "subject": SUBJECT,
                    "unit": str(unit),
                    "source": file
                }],
                ids=[f"{SUBJECT}_{doc_id}"]
            )
            doc_id += 1
            chunks_added += 1

    print(f"âœ… DONE | files={files_processed}, chunks={chunks_added}")
    print("ğŸ“Š FINAL CHROMA COUNT:", collection.count())


if __name__ == "__main__":
    ingest()
